---
title: 'Building up the Rusty Llama'
excerpt: "Great tutorials come up everyday. Some of them I just cannot ignore
and this is one of them. Code to the Moon released a video about creating a Chat
bot with access to a Huggingface LLM. I would like to see if it works on my
machine. Let's try!"
coverImage: '/assets/blog/img_bin/building_the_rusty_llama.png'
date: '2023-07-27T05:05:14.845Z'
author:
  name: 'Justin Bender'
  picture: '/assets/blog/authors/bender.png'
ogImage:
  url: '/assets/blog/img_bin/building_the_rusty_llama.png'
---

# Building up the Rusty Llama

> 💬 This is from a video created and produced by Code to the Moon. I appreciate the time he put into learning these technologies and I recommend watching the video yourself. If this little guide can help you, perfect!

> This project involves Rust 🦀 to you have to make sure that you have it downloaded as well as all of the other packages.

## Project links

* [Build a Full Stack Chatbot in Rust (feat. Leptos & Rustformeres) - Code to the Moon](https://www.youtube.com/watch?v=vAjle3c9Xqc)
* [Rust🦀](https://www.rust-lang.org/)
* [Wizard-Vicuna-7b-Uncensored-GGML](https://huggingface.co/TheBloke/Wizard-Vicuna-7B-Uncensored-GGML/tree/main)
* [Cargo Generate](https://github.com/cargo-generate/cargo-generate)
* [Leptos](https://leptos.dev/)
* [trunk](https://trunkrs.dev/)
* [NixOS](https://nixos.org/)
* [WASM](https://webassembly.org/)
* [Rustformers/llm](https://github.com/rustformers/llm)
* [Tailwind CSS](https://tailwindcss.com/)

---

Before we begin let's start with a little background of what we are building and what I am using at this moment for my operation system. I'm not using a normal distribution on Linux. We are using a form of NixOS. There might be some pieces missing from this explanation like `git` or other packages that are expected to already be on your machine.

Inside of your `/etc/nixos/configuration.nix` we need to add a few packages to make everything work.

* `pkg-config`
* `openssl`
* `binaryen`
* `sass`

Not 100% sure if needed but added in and don't plan to debug to see if I can take it out.

* `libiconv`
* `libgudev`

Now why do we need to have these packages? Well it's because the cargo crates that we plan to install will require them.

* `Trunk`
* `cargo-leptos`
* `cargo-generate`

```bash
❯ cargo install trunk cargo-leptos cargo-generate
```

Packages included in our configuration file may download automatically on the system that you are using. Since I'm on NixOS I have to handle these. This is fine but I also needed to add a path to `openssl` because the `pkg-config` could not locate everything as needed. Using `find /nix/store -name "openssl*"` I was able to find the location that I needed to use.

The path that I found for example was something like this:

```bash
❯ export PKG_CONFIG_PATH=/nix/store/z4vl5vjz1a479wmbm10mhdpqygg5b3vl-system-path/lib/pkgconfig:$PKG_CONFIG_PATH
```

Why couldn't I just use:

```bash
❯ /run/current-system/sw/lib/pkgconfig
```

I'm not 100% sure but it did not work that way and accurately find the path. It would keep failing. So we just have to set it to the `/nix/store` path.

At this point we should be able to download `cargo-leptos` and it should download. Now it's time to start working on the project.

## Let's start building out frontend

* Create the project and go into the project folder. Using the basic `leptos` setup and `actix`

```bash
❯ cargo leptos new --git leptos-rs/start
```

This will ask us the name we would like to use. Let's just pick `rusty-llama`

What is happening here? We are using a lot of the crates downloaded already `cargo generate` & `cargo leptos` to generate our project.

> 🛑 Explaining the internals of Leptos is out of scope for this project. There is both a server and a frontend. Lot's of code going on. So please look through it and maybe watch the youtube video connected to this tutorial

The basic file structure of our project looks like this:

```bash
❯ tree --gitignore
.
├── assets
│   └── favicon.ico
├── Cargo.lock
├── Cargo.toml
├── end2end
│   ├── package.json
│   ├── package-lock.json
│   ├── playwright.config.ts
│   └── tests
│       └── example.spec.ts
├── LICENSE
├── README.md
├── rust-toolchain.toml
├── src
│   ├── app.rs
│   ├── lib.rs
│   └── main.rs
└── style
    └── main.scss

6 directories, 16 files
```

We want to add a few files `conversation.rs` and `mod.rs` inside of a `model` directory. That lives inside of the `src` directory.

```bash
└── src
    ├── app.rs
    ├── lib.rs
    ├── main.rs
    └── model
        ├── conversation.rs
        └── mod.rs
```

Inside of the `mod.rs` file should just include the `conversation` to make it accessible and public to the `lib.rs`. So we will have to include a few lines of code inside of both `mod.rs` and `lib.rs` like so:

`mod.rs`:

```rust
pub mod conversation;
```

There is only one line that is added to this next file right now. `mod model`. This allows the project to know that the model module exists for this project.
`lib.rs`:

```rust
pub mod app;
mod model;

use cfg_if::cfg_if;

cfg_if! {
if #[cfg(feature = "hydrate")] {

  use wasm_bindgen::prelude::wasm_bindgen;

    #[wasm_bindgen]
    pub fn hydrate() {
      use app::*;
      use leptos::*;

      console_error_panic_hook::set_once();

      leptos::mount_to_body(move |cx| {
          view! { cx, <App/> }
      });
    }
}
}
```

Now that we have the module working. We want to build up our structs to handle the conversations we will have with the Large Language Model.

`model/conversation.rs`:

```rust
use serde::{Deserialize, Serialize};

#[derive(Serialize, Deserialize, Clone, Debug)]
pub struct Conversation {
    pub messages: Vec<Message>
}

impl Conversation {
    pub fn new() -> Conversation {
        Conversation {
            messages: Vec::new()
        }
    }
}

#[derive(Serialize, Deserialize, Clone, Debug)]
pub struct Message {
    pub user: bool,
    pub text: String,
}
```

If you notice we are using `serde` so we must include that in our project with:

```bash
❯ cargo add serde -F derive
```

Looking in our `conversation.rs` file we have a few different structures.

* Conversation
* Message

This is a very simple design. We will have text inside of the message and we will have a boolean that tells us who is talking. The user or the model response. We also include an implementation of `Conversation` to have a `new` function. That will return a `Converstation`. Which is a vector of messages.

Now that we have created the structures for our project we can start working on the frontend for a bit.
