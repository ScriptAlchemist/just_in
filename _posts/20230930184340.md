---
title: 'Jumping back into Rust ðŸ¦€ after a break'
excerpt: 'Rust is one of the most complicated languages for me to learn. It is
not extremely hard to really understand what is going on. It just requires a bit
more time and effort. For this post we will start on day one of Comprehensive
Rust by Google'
coverImage: '/assets/blog/img_bin/comprehensive_rust.png'
date: '2023-09-30T18:43:40.914Z'
author:
  name: 'Justin Bender'
  picture: '/assets/blog/authors/bender.png'
ogImage:
  url: '/assets/blog/img_bin/'
---

# Jumping back into Rust ðŸ¦€ after a break

### What are the goals of this course?

* Give you a comprehensive understanding of the Rust syntax and language.
* Enable you to modify existing programs and write new programs in Rust.
* Show you common Rust idioms.

#### Topics I would like to explore next:

* [Concurrency](https://google.github.io/comprehensive-rust/concurrency.html)

### Non-goals

Rust is a large language and we won't be able to cover all of it in a few days.
Some non-goals of this course are:

* Learning how to develop macros. You should go to the rust book or rust by
  example book.

---

* Day 1: Basic Rust, syntax, control flow, creating and consuming values.
* Day 2: Memory management, ownership, compound data types, and the standard
  library.
* Day 3: Generics, traits, error handling, testing, and unsafe Rust.

I think I'm going to skip most of this and go right into the concurrency
sections. It's a bit more interesting to me over just going over the items I've
already looked at for a while.

---

## Concurrency In Rust

Setup the project:

```rust
cargo init concurrency
cd concurrency
cargo add tokio --features full
cargo run
```

Rust has full support for concurrency using OS threads with mutexes and channels

The Rust type system plays an important role in making many concurrency bugs
compile time bugs. This is often referred to as fearless concurrency since you
can rely on the compiler to ensure correctness at runtime.

```rust
use std::thread;
use std::time::Duration;

fn main() {
    thread::spawn(|| {
        for i in 1..10 {
            println!("Count in thread: {i}!");
            thread::sleep(Duration::from_millis(5));
        }
    });

    for i in 1..5 {
        println!("Main thread: {i}");
        thread::sleep(Duration::from_millis(5));
    }
}
```

* Threads are all daemon threads, the main thread does not wait for them.
* Thread panics are independent of eachother.
  - Panics can carry a payload, which can be unpacked with `downcase_ref`.


* Notice that the thread is stopped before it reaches 10 â€” the main thread is not waiting.

* Use let handle = thread::spawn(...) and later handle.join() to wait for the thread to finish.

* Trigger a panic in the thread, notice how this doesnâ€™t affect main.

*  Use the Result return value from handle.join() to get access to the panic payload. This is a good time to talk about Any.

```rust
use std::thread;
use std::time::Duration;

fn main() {
    let handle = thread::spawn(|| {
        for i in 1..10 {
            println!("Count in thread: {i}!");
            if i == 2 { panic!("Thread paniced at {}", i); }
            thread::sleep(Duration::from_millis(5));
        }
    });

    for i in 1..5 {
        println!("Main thread: {i}");
        thread::sleep(Duration::from_millis(5));
    }

    let result = handle.join();

    match result {
        Ok(_) => println!("Thread completed successfully."),
        Err(e) => {
            println!("Thread panicked: {:?}", e);
            if let Some(payload) = e.downcast_ref::<&str>() {
                println!("Panic payload {}", payload);
            } else if let Some(payload) = e.downcast_ref::<String>() {
                println!("Panic payload {}", payload);
            } else {
                println!("Unknown panic payload type.");
            }
        }
    }
}
```

This will make the extra thread fail at the 2nd loop. It still prints an
interesting error that I don't understand, but we will continue on in hopes that
it will become more clear in the future.

Normal threads cannot borrow from their environment.

```rust
use std::thread;

fn foo() {
    let s = String::from("Hello");
    thread::spawn(|| {
        println!("Length: {}", s.len());
    });
}

fn main() {
    foo();
}
```

However, you can used a scoped thread for this:

```rust
use std::thread;

fn foo() {
    let s = String::from("Hello");
    thread::scope(|scope| {
        scope.spawn(|| {
            println!("Length: {}", s.len());
        });
    });
}

fn main() {
    foo();
}
```

* The reason for that is that when the `thread::scope` function completes, all
  the threads are guaranteed to be joined, so they can return borrowed data.
* Normal Rust borrowing rules apply: you can either borrow mutably by one
  thread, or immutably by any number of threads.


#### Channels

Rust channels have two parts: a `Sender<T>` and a `Receiver<T>`. The two parts
are connected via the channel, but only see the end-points.

```rust
use std::sync::mpsc;

fn main() {
    let (tx, rx) = mpsc::channel();

    tx.send(10).unwrap();
    tx.send(20).unwrap();

    println!("Received: {:?}", rx.recv());
    println!("Received: {:?}", rx.recv());

    let tx2 = tx.clone();
    tx2.send(30).unwrap();
    println!("Received: {:?}", rx.recv());
}
```

* `mpsc` stands for Multi-Producer, Single-Consumer. `Sender` and `SyncSender`
  implement `Clone` (so you can make multiple producers) but `Receiver` does
  not.
* `send()` and `recv()` return `Result`. If they return `Err`, it means the
  counterpart `Sender` or `Receiver` is dropped and the channel is closed.

#### Unbounded Channels

You get an unbounded and asynchronous channel with `mpsc::channel()`:

```rust
use std::sync::mpsc;
use std::thread;
use std::time::Duration;

fn main() {
    let (tx, rx) = mpsc::channel();

    thread::spawn(move || {
        let thread_id = thread::current().id();
        for i in 1..10 {
            tx.send(format!("Message {i}")).unwrap();
            println!("{thread_id:?}: sent Message {i}");
        }
        println!("{thread_id:?}: done");
    });
    thread::sleep(Duration::from_millis(100));

    for msg in rx.iter() {
        println!("Main: got {msg}");
    }
}
```

#### Bounded Channels

With bounded channels (synchronous) channels, `send` can block the current
thread:

```rust
use std::sync::mpsc;
use std::thread;
use std::time::Duration;

fn main() {
    let (tx, rx) = mpsc::sync_channel(4);

    thread::spawn(move || {
        let thread_id = thread::current().id();
        for i in 1..10 {
            tx.send(format!("Message {i}")).unwrap();
            println!("{thread_id:?}: sent Message {i}");
        }
        println!("{thread_id:?}: done");
    });
    thread::sleep(Duration::from_millis(100));

    for msg in rx.iter() {
        println!("Main: got {msg}");
    }
}
```

The output is a bit strange to me.

```text
   Compiling concurrency v0.1.0 (/Users/justinbender/projects/rust_programs/concurrency)
    Finished dev [unoptimized + debuginfo] target(s) in 0.14s
     Running `target/debug/concurrency`
ThreadId(2): sent Message 1
ThreadId(2): sent Message 2
ThreadId(2): sent Message 3
ThreadId(2): sent Message 4
Main: got Message 1
Main: got Message 2
Main: got Message 3
Main: got Message 4
Main: got Message 5
ThreadId(2): sent Message 5
ThreadId(2): sent Message 6
ThreadId(2): sent Message 7
ThreadId(2): sent Message 8
ThreadId(2): sent Message 9
ThreadId(2): done
Main: got Message 6
Main: got Message 7
Main: got Message 8
Main: got Message 9
[Finished running. Exit status: 0]
```

* Calling `send` will block the current thread until there is space in the
  channel for the new message. The thread can be blocked indefinitely if there
  is nobody who reads from the channel.
* A call to `send` will abort with an error ( that is why it returns `Result`)
  if the channel is closed. A channel is closed when the receiver is dropped.
* A bounded channel with a size of zero is called a "rendezvous channel`. Every
  send will block the current thread until another thread calls `read`.

#### Send and Sync

How does Rust know to forbid sharing access across threads? The answer is in two
traits:

* `Send`: a type `T` is `Send` if it is safe to move a `T` across a thread
  boundary.
* `Sync`: a type `T` is `Sync` if it is safe to move a `&T` across a thread
  boundary.

`Send` and `Sync` are unsafe traits. The compiler will automatically derive them
for your types as long as they only contain `Send` and `Sync` types. You can
also implement them manually when you know it is valid.

* One can think of these traits as markers that the type has certain
  thread-safety properties.
* They can be used in the generic constraints as normal traits.

#### Send

> A type `T` is `Send` if it is safe to move a `T` value to another thread.

The effect of moving ownership to another thread is that destructors wil run in
that thread. So the question is when you can allocate a value in one thread and
deallocate it in another.

An example, a connection to the SQLite library must only be accessed form a
single thread.

#### Sync

> A type `T` is `Sync` if it is safe to access `T` value from multiple threads
at the same time.

More precisely, the definition is:

> `T` is `Sync` if and only if `&T` is `Send`

This statement is essentially a shorthand way of saying that if a type is
thread-safe for shared use, it is also thread-safe to pass references of it
across threads.

This is because if a type is Sync it means that it can be shared across multiple
threads without the risk of data races or other synchronization issues, so it is
safe to move it to another thread. A reference of the type is also safe to move
to another thread, because the data it references can be accessed for any thread
safely.

### Examples

#### Send + Sync

Most types you come across are `Send + Sync`:

* `i8`, `f32`, `bool`, `char`, `&str`, ...
* `(T1, T2)`, `[T; N]`, `&[T]`, `struct { x: T }`, ...
* `String, Option<T>`, `Vec<T>`, `Box<T>`, ...
* `Arc<T>`: Explicitly thread-safe via atomic reference count.
* `Mutex<T>`: Explicitly thread-safe via internal locking
* `AtomicBool`, `AtomicU8`, ...: Uses special atomic instructions.

The generic types are typically `Send + Sync` when the type parameters are
`Send + Sync`.

#### Send + !Sync

These types can be moved to other threads, but they're not thread-safe.
Typically because of interior mutability.

* `mpsc::Sender<T>`
* `mpsc::Receiver<T>`
* `Cell<T>`
* `RefCell<T>`

#### !Send + Sync

These types are thread safe, but they cannot be moved to another thread:

* `MutexGuard<T>`: Uses OS level primitives which must be deallocated on the
  thread which created them.

#### !Send + !Sync

These types are not thread-safe and cannot be moved to other threads:

* `Rc<T>`: each `Rc<T>` has a reference to and `RcBox<T>`, which contains a
  non-atomic reference count.
* `*const T`, `*mut T`: Rust assumes raw pointers may have special concurrency
  considerations.

### Shared state

Rust uses the type system to enforce synchronization of shared data. This is
primarily done via two types.

* `Arc<T>`, atomic reference counted `T`: handles shared between threads and
  takes care to deallocate `T` when the last reference is dropped.
* `Mutex<T>`: ensures mutability exclusive access to the `T` value.

#### Arc

`Arc<T>` allows shared read-only access via `Arc::clone`:

```rust
use std::thread;
use std::sync::Arc;

fn main() {
    let v = Arc::new(vec![10, 20, 30]);
    let mut handles = Vec::new();
    for _ in 1..5 {
        let v = Arc::clone(&v);
        handles.push(thread::spawn(move || {
            let thread_id = thread::current().id();
            println!("{thread_id:?}: {v:?}");
        }));
    }
    handles.into_iter().for_each(|h| h.join().unwrap());
    println!("v: {v:?}");
}
```

* `Arc` stands for "Atomic Reference Counted", a thread safe version or `Rc that
  used atomic operations.
* `Arc<T>` implements `Clone` whether or not `T` does. It implements `Send` and
  `Sync` if and only if `T` implements them both.
* `Arc::clone()` has the cost of atomic operations that get executed, but after
  that the use of the `T` is free.
* Beware of reference cycles, `Arc` does not use a garbage collector to detect
  them.
  - `std::sync::Weak` can help.

